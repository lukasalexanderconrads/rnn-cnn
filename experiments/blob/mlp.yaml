name: blob-hard/mlp/
device: cuda:0
num_runs: 20
seed: 1

model:
  module: lab.models.simple
  name: MLP
  args:
    layer_dims: [!!python/tuple [2, 2, 2, 2, 2, 2]]

loader:
  module: lab.data.dataloaders
  name: DataLoaderBlob
  args:
    batch_size: 100


optimizer:
  module: torch.optim
  name: Adam
  args:
    lr: .001

trainer:
  module: lab.trainer
  name: Trainer
  args:
    n_epochs: 1000
    bm_metric: cross_entropy
    early_stop_criterion: 300 # if no improvement over this many epochs, stop training
    log_dir: results
    save_dir: results
