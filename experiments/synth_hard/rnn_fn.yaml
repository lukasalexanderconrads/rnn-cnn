name: synth_hard/rnn_fn/
device: cuda:0
num_runs: 1
seed: 1

model:
  module: lab.models.recurrence_function
  name: LearnableRNN
  args:
    fc_dims: !!python/tuple []
    rnn_dim: 2
    head_dims: !!python/tuple []
    max_rec: [2]               # maximum number of recurrences
    rec_fn_layers: [!!python/tuple [2]]
    skip_connections: false   # if skip connection is used in recurrent layer

loader:
  module: lab.dataloaders
  name: DataLoaderSyntheticHard
  args:
    batch_size: 100
    valid_fraction: .1
    n_samples: 1.0e5
    n_features: 2
    seed: 1

trainer:
  module: lab.trainer
  name: Trainer
  args:
    n_epochs: 100
    bm_metric: loss
    log_dir: results
    save_dir: results

    #loss_scheduler: None # fraction of total training that a given loss type is active
      #first_step: .0    # loss is computed for the first step's output
      #every_step: .0    # loss is computed for every step's output
      # remaining time:   loss is computed for the final step's output

    #max_rec_scheduler: # linear increase from min to max
      #min: 1
      #max: 2

#TODO: add tau scheduler for gumbel softmax
